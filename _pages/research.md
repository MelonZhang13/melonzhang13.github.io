---
layout: archive
title: ""
permalink: /research/
author_profile: true
redirect_from:
  - /research
---

{% include base_path %}

<style>
h2 {
    margin-bottom: 0.5em; /* 调整为你认为合适的值 */
}

p {
    margin-top: 0em;
    margin-bottom: 0.5em; /* 调整为你认为合适的值 */
}

blockquote {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
}

ul {
    margin-top: 0em;
    margin-bottom: 0.5em; /* 调整为你认为合适的值 */
}

li {
    margin-bottom: 0.05em; /* 调整为你认为合适的值 */
    line-height: 1.25; /* 调整行高来影响行间距 */
}
</style>

## <font color=RoyalBlue>Research 1: Desktop Gesture Interaction System in Virtual Reality</font>
>**Paper :** **Ruisheng Zhang** and Xiaozhou Zhou*. BeyondDeskVR: An Extended Virtual Hand Interaction System in Virtual Reality. _Behaviour & Information Technology_, Major Revision. 

The main contents of this research are as follows:
- Aim to ensure low fatigue, prolonged, and stable interaction input for a seated working scenario in VR.
- Propose an extended virtual hand interaction system, which integrates desktop and mid-air gesture interactions.
- Prototype a desktop gesture recognition hardware based on infrared laser projection sensing technology.
- Develop a desktop gesture recognition algorithm based on OpenCV, integrating the designed gestures into VR.

<!-- <div style="text-align: left;">
  <iframe src="https://drive.google.com/file/d/15m0nlETw7DChDeTUgcwCsFU1kUZ_uF2U/preview" width="960" height="540" style="border: none; display: block; margin: 0;" allow="autoplay"></iframe>
</div> -->
<div class="video-container">
  <iframe src="https://drive.google.com/file/d/15m0nlETw7DChDeTUgcwCsFU1kUZ_uF2U/preview" frameborder="0" allow="autoplay"></iframe>
</div>
<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #fff;
  text-align: left; /* Align video to the left */
}
.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: #fff;
  border: none;
}
/* Media query for larger screens */
@media (min-width: 768px) {
  .video-container {
    max-width: 960px; /* Optional: you can set a max-width for larger screens */
    margin: 0; /* Align to the left */
  }
}
</style>


<br>

## <font color=RoyalBlue>Research 2: Hierarchical Human Intention Recognition</font>

> **Paper :** **Ruisheng Zhang**, Xuyi Qiu, Jichen Han, Hang Wu, Minglang Li and Xiaozhou Zhou*. A Hierarchical Intention Recognition Framework in Intelligent Human‒Computer Interactions for Complex Tasks: The Case of Helicopter and Drone Collaborative Wildfire Rescue Missions. _Engineering Applications of Artificial Intelligence_, Under Review. 

The main contents of this research are as follows:

- Propose a general hierarchical intention recognition framework for complex tasks.
- Develop an 1DCNN+Bi-LSTM neural network and dyamic Bayesian network (DBN) to recognize human intention.
-	Combine task analysis and machine learning to keep rationality and interpretability.
-	Input sensor-acquired situational and behavioural data without disrupting workflows.
- Serve as a foundation for building intelligent human-computer interaction system.



<div style="text-align:center;">
    <img src='/images/Hierarchical Intention Recognition Research Framework.png' style="width: 80%;">
</div>

<!-- - Conduct task analysis and collect operator behavioral datasets for complex flight tasks.
- Develop an 1DCNN+Bi-LSTM+Attention neural network for operator's interaction intention recognition.
- Develop a Dyamic Bayesian Network (DBN) for operator's task intention recognition.
- Achieve simultaneous recognition of dual-level intentions, serving as triggers for intelligent adaptive interfaces. -->

<!-- <div style="text-align:center;">
    <img src='/images/Hierarchical Intention Recognition.png'>
</div> -->

<!-- - Propose a general hierarchical intention recognition framework for complex tasks for building intelligent human‒machine interaction systems.
- Combine task analysis and machine learning to ensure the rationality of the task and sensitivity to human‒machine loop transformation.
- Develop an 1DCNN+Bi-LSTM+Attention neural network and Dyamic Bayesian Network (DBN) to recognize operator's interaction and task intention, respectively.
- Input sensor-acquired situational and behavioural data without disrupting workflows.
- Provide technical support for building intelligent human-machine interaction system. -->


