---
layout: archive
title: ""
permalink: /projects/
author_profile: true
redirect_from:
  - /projects
---

{% include base_path %}

<style>
h2 {
    margin-bottom: 0.5em; /* 调整为你认为合适的值 */
}

p {
    margin-top: 0em;
    margin-bottom: 0.5em; /* 调整为你认为合适的值 */
}

blockquote {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
}

ul {
    margin-top: 0em;
    margin-bottom: 0.5em; /* 调整为你认为合适的值 */
}

li {
    margin-bottom: 0.05em; /* 调整为你认为合适的值 */
    line-height: 1.25; /* 调整行高来影响行间距 */
}
</style>

<!--项目1 -->

## <font color=RoyalBlue>Project 1: Optimization For BeyondDeskVR</font>

>**Related Tools :** Unity3D, Deep Learning, PyTorch, LSTM, Barracuda, ONNX.<br>
>**Project Time :** 2024.07-2024.08.

My main works on this project are as follows:
- Solve the Heisenberg effect caused by the confirming movement in BeyondDeskVR.
- Build an experimental scene for random target tapping and collect real-time data.
- Utilize Pytorch to train an LSTM model for recognizing user's intended pointing.
- Utilize ONNX and barracuda to deploy the optimized model into Unity application.

The demonstration video can be accessed at : [<a href="https://drive.google.com/file/d/15mRp5jja0o2AGPGD9mG-QAwRr0v1xkWw/preview" style="color: RoyalBlue;">video</a>]


<!--项目2 -->

## <font color=RoyalBlue>Project 2: Data-driven Digital Vehicle Interface</font>

>**Related Tools :** Unity3D, TCP Communication, UGUI, Hotas System.<br>
>**Project Time :** 2023.10-2023.12.

My main works on this project are as follows:
- Utilize the Unity3D engine to validate self-designed/DIY vehicle digital interface.
- Serve as a platform for the ergonomics evaluation of vehicle interface.
- Achieve seamless communication between Unity and a vehicle simulation software by TCP protocol.
- Achieve data-driven dynamic displays for interface information.

The demonstration video can be accessed at : [<a href="https://drive.google.com/file/d/1srmF8avRm5r8ZGwj7VF5S3Xj97x6BZM0/preview" style="color: RoyalBlue;">video</a>]

<!-- <div class="video-container">
  <iframe src="https://drive.google.com/file/d/1srmF8avRm5r8ZGwj7VF5S3Xj97x6BZM0/preview" frameborder="0" allow="autoplay"></iframe>
</div>
<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #fff;
  text-align: left; /* Align video to the left */
}
.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: #fff;
  border: none;
}
/* Media query for larger screens */
@media (min-width: 768px) {
  .video-container {
    max-width: 960px; /* Optional: you can set a max-width for larger screens */
    margin: 0; /* Align to the left */
  }
}
</style> -->


<!--项目3 -->

## <font color=RoyalBlue>Project 3: Mid-Air Gesture Interaction for VR Sandbox</font>
>**Related Tools :** Unity3D, Oculus Intergration, Oculus Quest Pro.<br>
>**Project Time :** 2023.02-2023.06.

My main works on this project are as follows:
- Utilize the Unity3D engine and Oculus Intergration Package to develop mid-air gesture interaction function in VR.
- Achieve point, line, and area plotting functions based on mid-air gestures in virtual space.
- Utilize Bezier curves to display the trajectory of virtual objects.

The demonstration video can be accessed at : [<a href="https://drive.google.com/file/d/1viYKKfXuuXtIhxoKEFfOZJ6jhM7X50v-/preview" style="color: RoyalBlue;">video</a>]

<!-- <div class="video-container">
  <iframe src="https://drive.google.com/file/d/1viYKKfXuuXtIhxoKEFfOZJ6jhM7X50v-/preview" frameborder="0" allow="autoplay"></iframe>
</div>
<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #fff;
  text-align: left; /* Align video to the left */
}
.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: #fff;
  border: none;
}
/* Media query for larger screens */
@media (min-width: 768px) {
  .video-container {
    max-width: 960px; /* Optional: you can set a max-width for larger screens */
    margin: 0; /* Align to the left */
  }
}
</style> -->


<!--项目4 -->

## <font color=RoyalBlue>Project 4: Intelligent Future Vehicle Cockpit with Multi-Modal Interactions</font>

>**Related Tools :** Unity3D, Data-Driven User Interface, Leap Motion, Smart Eye, Windows Speech Recognition...<br>
>**Project Time :** 2022.08-2023.08.

My main works on this project are as follows:
- Utilize the Unity3D engine to develop multi-modal interaction functions
- Achieve gesture interaction, voice interaction,touch interaction, eye-tracking/eye-control and vehicle control.
- Achieve seamless communication between Unity and vehicle simulation software by TCP protocol
- Achieve data-driven dynamic displays for interface information.

<!-- <div style="text-align:center;">
    <img src='/images/Intelligent Flight Cockpit with Multi-Modal Interactions.png' style="width: 80%;">
</div> -->





