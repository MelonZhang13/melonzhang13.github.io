---
layout: archive
title: ""
permalink: /projects/
author_profile: true
redirect_from:
  - /projects
---

{% include base_path %}

<!--项目1 -->

## <font color=RoyalBlue>Project 1: Optimization For BeyondDeskVR</font>

>**Related Tools :** Unity3D, Deep Learning, PyTorch, LSTM, Barracuda, ONNX.<br>
>**Project Time :** 2024.07-2024.08.

My main works on this project are as follows:
- Solve the Heisenberg effect caused by the confirming movement in BeyondDeskVR.
- Build an experimental scene for random target tapping and collect real-time data.
- Utilize Pytorch to train an LSTM model for recognizing user's intended pointing.
- Utilize ONNX and barracuda to deploy the optimized model into Unity application.

<div class="video-container">
  <iframe src="https://drive.google.com/file/d/15mRp5jja0o2AGPGD9mG-QAwRr0v1xkWw/preview" frameborder="0" allow="autoplay"></iframe>
</div>
<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #fff;
  text-align: left; /* Align video to the left */
}
.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: #fff;
  border: none;
}
/* Media query for larger screens */
@media (min-width: 768px) {
  .video-container {
    max-width: 960px; /* Optional: you can set a max-width for larger screens */
    margin: 0; /* Align to the left */
  }
}
</style>


<!--项目2 -->

<br>

## <font color=RoyalBlue>Project 2: Data-driven Digital Cockpit Interface</font>

>**Related Tools :** Unity3D, DCS World, TCP Communication, UGUI, Hotas System.<br>
>**Project Time :** 2023.10-2023.12.

My main works on this project are as follows:
- Utilize the Unity3D engine to validate self-designed/DIY cockpit digital interface.
- Serve as a platform for the ergonomics evaluation of aviation interface.
- Achieve seamless communication between Unity and DCS World (a flight simulation software) by TCP protocol.
- Achieve data-driven dynamic displays for HUD and POP interface information.

<div class="video-container">
  <iframe src="https://drive.google.com/file/d/1srmF8avRm5r8ZGwj7VF5S3Xj97x6BZM0/preview" frameborder="0" allow="autoplay"></iframe>
</div>
<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #fff;
  text-align: left; /* Align video to the left */
}
.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: #fff;
  border: none;
}
/* Media query for larger screens */
@media (min-width: 768px) {
  .video-container {
    max-width: 960px; /* Optional: you can set a max-width for larger screens */
    margin: 0; /* Align to the left */
  }
}
</style>


<!--项目3 -->

<br>

## <font color=RoyalBlue>Project 3: Mid-Air Gesture Interaction for VR Naval Command Systems</font>
>**Related Tools :** Unity3D, Oculus Intergration, Oculus Quest Pro.<br>
>**Project Time :** 2023.02-2023.06.

My main works on this project are as follows:
- Utilize the Unity3D engine and Oculus Intergration Package to develop mid-air gesture interaction function in VR.
- Achieve point, line, and area plotting functions based on airborne gestures in virtual space.
- Utilize Bezier curves to display the trajectory of airborne targets.

<!-- <div style="text-align: left;">
  <iframe src="https://drive.google.com/file/d/15m0nlETw7DChDeTUgcwCsFU1kUZ_uF2U/preview" width="960" height="540" style="border: none; display: block; margin: 0;" allow="autoplay"></iframe>
</div> -->
<div class="video-container">
  <iframe src="https://drive.google.com/file/d/1viYKKfXuuXtIhxoKEFfOZJ6jhM7X50v-/preview" frameborder="0" allow="autoplay"></iframe>
</div>
<style>
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 aspect ratio */
  height: 0;
  overflow: hidden;
  max-width: 100%;
  background: #fff;
  text-align: left; /* Align video to the left */
}
.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: #fff;
  border: none;
}
/* Media query for larger screens */
@media (min-width: 768px) {
  .video-container {
    max-width: 960px; /* Optional: you can set a max-width for larger screens */
    margin: 0; /* Align to the left */
  }
}
</style>


<!--项目4 -->

<br>

## <font color=RoyalBlue>Project 4: Intelligent Future Flight Cockpit with Multi-Modal Interactions</font>

>**Related Tools :** Unity3D, DCS World, DDS Communication, Data-Driven User Interface, Leap Motion, Smart Eye, Windows Speech Recognition...<br>
>**Project Time :** 2022.08-2023.08.

My main works on this project are as follows:
- Utilize the Unity3D engine to develop multi-modal interaction functions
- Achieve gesture interaction, voice interaction,touch interaction, eye-tracking/eye-control and flight control.
- Achieve seamless communication between Unity and DCS World (a flight simulation software) by DDS protocol
- Achieve data-driven dynamic displays for HUD and POP interface information.

<div style="text-align:center;">
    <img src='/images/Intelligent Flight Cockpit with Multi-Modal Interactions.png' style="width: 80%;">
</div>





